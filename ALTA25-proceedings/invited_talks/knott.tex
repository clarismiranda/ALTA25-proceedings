Like most AI language researchers these days, I divide my time between being amazed by the quality of our new large language models, and worrying about how these models will impact society. In an attempt to reconcile these two instincts, my work for the last few years has focussed on contributing to conversations about LLM regulation, where people who understand the technology at issue have many important roles to play.

In this talk I’ll discuss a few ongoing conversations I’m involved in - and hopefully connect with people at ALTA who are having similar conversations. One discussion is about transparency for AI-generated content. My group at the Global Partnership on AI helped to define a clause in the EU’s AI Act, requiring providers of AI content generators to ensure their content is ‘detectable’. A key debate at present is about enforcement: what can we require of providers, given the state-of-the-art in AI content detection schemes? Another discussion is about transparency of social media platforms. The EU’s Digital Services Act contains provisions allowing vetted external researchers to access the largest platforms, to study ‘societal risks’ (and their mitigation). Now these provisions are in place, what are the most important questions that should be asked, and what methods are most suitable? (I co-founded a grouping of social data science researchers, to help answer that question.) A final discussion is about accountability for AI training sets. I am particularly interested in the labelled datasets created by Silicon Valley companies, to align their LLMs, and to train their harmful content classifiers. A great deal of power resides with the annotators who provide labels for these datasets. But we often know little about how annotators are chosen, and about the guidelines they follow. My group at GPAI has proposed that labels could be provided ‘democratically’, by consulting a representative sample of citizens or users, through a process akin to opinion polling. I’ll finish by discussing how this idea could feature in the governance of ’sovereign LLMs’ developed in Australia and New Zealand.